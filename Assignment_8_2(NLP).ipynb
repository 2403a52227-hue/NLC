{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMiUIpO0+IkZXVp68cgVH+2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2403a52227-hue/-NLP/blob/main/Assignment_8_2(NLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "from collections import Counter\n",
        "from nltk.util import ngrams\n",
        "import math\n",
        "from collections import defaultdict\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from collections import Counter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1loWsRGQIbf",
        "outputId": "22ab9a43-f4ff-48e1-edb3-31498a3a72c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b74EGODxHHkT"
      },
      "outputs": [],
      "source": [
        "d1=\"data science is fun\"\n",
        "d2=\"machine learning is powerful\"\n",
        "d3=\"natural language processing is interesting\"\n",
        "d4=\"deep learning uses neural networks\"\n",
        "d5=\"python is popular for ai\"\n",
        "d6=\"ai is transforming industries\"\n",
        "d7=\"models learn from data\"\n",
        "d8=\"statistics helps in analysis\"\n",
        "d9=\"big data requires computation\"\n",
        "d10=\"algorithms solve problems\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine all documents\n",
        "dataset = [d1, d2, d3, d4, d5, d6, d7, d8, d9, d10]\n",
        "text = \" \".join(dataset)\n",
        "text = text.lower()\n",
        "import re, string\n",
        "text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokens = word_tokenize(text)\n",
        "print(\"Tokens:\\n\", tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zh4J1xsYPkC9",
        "outputId": "ec381eb9-c459-42f4-b200-0adb23e76eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens:\n",
            " ['data', 'science', 'is', 'fun', 'machine', 'learning', 'is', 'powerful', 'natural', 'language', 'processing', 'is', 'interesting', 'deep', 'learning', 'uses', 'neural', 'networks', 'python', 'is', 'popular', 'for', 'ai', 'ai', 'is', 'transforming', 'industries', 'models', 'learn', 'from', 'data', 'statistics', 'helps', 'in', 'analysis', 'big', 'data', 'requires', 'computation', 'algorithms', 'solve', 'problems']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "word_counts = Counter(tokens)\n",
        "rare_words = {word for word, count in word_counts.items() if count == 1}\n",
        "print(\"Rare Words:\\n\", rare_words)\n",
        "tokens_unk = [word if word not in rare_words else \"UNK\" for word in tokens]\n",
        "print(\"\\nTokens After UNK:\\n\", tokens_unk)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPMGbAK0TDoC",
        "outputId": "90330562-cde7-45b3-d9f4-816481bff725"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rare Words:\n",
            " {'algorithms', 'from', 'statistics', 'transforming', 'uses', 'neural', 'science', 'networks', 'popular', 'natural', 'analysis', 'computation', 'fun', 'python', 'powerful', 'big', 'helps', 'for', 'interesting', 'solve', 'language', 'models', 'processing', 'machine', 'learn', 'deep', 'industries', 'in', 'requires', 'problems'}\n",
            "\n",
            "Tokens After UNK:\n",
            " ['data', 'UNK', 'is', 'UNK', 'UNK', 'learning', 'is', 'UNK', 'UNK', 'UNK', 'UNK', 'is', 'UNK', 'UNK', 'learning', 'UNK', 'UNK', 'UNK', 'UNK', 'is', 'UNK', 'UNK', 'ai', 'ai', 'is', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'data', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK', 'data', 'UNK', 'UNK', 'UNK', 'UNK', 'UNK']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**N-GRAM MODEL**"
      ],
      "metadata": {
        "id": "0EIdvlnLURL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.util import ngrams\n",
        "\n",
        "def build_ngram(tokens, n):\n",
        "    return Counter(ngrams(tokens, n))\n",
        "# Without UNK\n",
        "unigram = build_ngram(tokens, 1)\n",
        "bigram = build_ngram(tokens, 2)\n",
        "trigram = build_ngram(tokens, 3)\n",
        "# With UNK\n",
        "unigram_unk = build_ngram(tokens_unk, 1)\n",
        "bigram_unk = build_ngram(tokens_unk, 2)\n",
        "trigram_unk = build_ngram(tokens_unk, 3)\n",
        "print(\"Sample Unigram:\\n\", list(unigram.items())[:5])\n",
        "print(\"Sample Bigram:\\n\", list(bigram.items())[:5])\n",
        "print(\"Sample Trigram:\\n\", list(trigram.items())[:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HIPlDkqgUKrd",
        "outputId": "8593b463-8655-402c-d0bb-f3b2cc5d4c73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Unigram:\n",
            " [(('data',), 3), (('science',), 1), (('is',), 5), (('fun',), 1), (('machine',), 1)]\n",
            "Sample Bigram:\n",
            " [(('data', 'science'), 1), (('science', 'is'), 1), (('is', 'fun'), 1), (('fun', 'machine'), 1), (('machine', 'learning'), 1)]\n",
            "Sample Trigram:\n",
            " [(('data', 'science', 'is'), 1), (('science', 'is', 'fun'), 1), (('is', 'fun', 'machine'), 1), (('fun', 'machine', 'learning'), 1), (('machine', 'learning', 'is'), 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def unigram_probability(model, word, total_words, vocab_size, k=0):\n",
        "    count = model.get((word,), 0)\n",
        "    return (count + k) / (total_words + k * vocab_size)\n"
      ],
      "metadata": {
        "id": "S_fQlp9MUlb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def perplexity(tokens, model, vocab_size, k=0):\n",
        "    total_words = sum(model.values())\n",
        "    N = len(tokens)\n",
        "    log_prob = 0\n",
        "\n",
        "    for word in tokens:\n",
        "        prob = unigram_probability(model, word, total_words, vocab_size, k)\n",
        "        log_prob += math.log2(prob)\n",
        "\n",
        "    return 2 ** (-log_prob / N)\n"
      ],
      "metadata": {
        "id": "O_c4_SmaVdq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**predicting probability for next words**"
      ],
      "metadata": {
        "id": "VuI-Mc_EXm0m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unigram P(w)\n",
        "def unigram_prob(w, unigram_counts, V, k=1):\n",
        "    total = sum(unigram_counts.values())\n",
        "    count = unigram_counts.get((w,), 0)\n",
        "    return (count + k) / (total + k*V)\n",
        "# Bigram P(w2 | w1)\n",
        "def bigram_prob(w1, w2, bigram_counts, unigram_counts, V, k=1):\n",
        "    count_w1_w2 = bigram_counts.get((w1, w2), 0)\n",
        "    count_w1 = unigram_counts.get((w1,), 0)\n",
        "    return (count_w1_w2 + k) / (count_w1 + k*V)\n",
        "# Trigram P(w3 | w1, w2)\n",
        "def trigram_prob(w1, w2, w3, trigram_counts, bigram_counts, V, k=1):\n",
        "    count_w1_w2_w3 = trigram_counts.get((w1, w2, w3), 0)\n",
        "    count_w1_w2 = bigram_counts.get((w1, w2), 0)\n",
        "    return (count_w1_w2_w3 + k) / (count_w1_w2 + k*V)\n"
      ],
      "metadata": {
        "id": "EIkm38itVg_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unigram prediction\n",
        "def predict_next_word_unigram(unigram_counts, V):\n",
        "    # Return word with maximum probability\n",
        "    probs = {w[0]: unigram_prob(w[0], unigram_counts, V) for w in unigram_counts}\n",
        "    return max(probs, key=probs.get)\n",
        "# Bigram prediction\n",
        "def predict_next_word_bigram(prev_word, bigram_counts, unigram_counts, V):\n",
        "    probs = {w: bigram_prob(prev_word, w, bigram_counts, unigram_counts, V) for w in vocab}\n",
        "    return max(probs, key=probs.get)\n",
        "# Trigram prediction\n",
        "def predict_next_word_trigram(prev_word1, prev_word2, trigram_counts, bigram_counts, V):\n",
        "    probs = {w: trigram_prob(prev_word1, prev_word2, w, trigram_counts, bigram_counts, V) for w in vocab}\n",
        "    return max(probs, key=probs.get)\n"
      ],
      "metadata": {
        "id": "es3WjcspXtGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define V (vocabulary size)\n",
        "V = len(unigram)\n",
        "# Define vocab (set of unique words)\n",
        "vocab = {word[0] for word in unigram.keys()}\n",
        "next_word_uni = predict_next_word_unigram(unigram, V)\n",
        "print(\"Next word prediction (Unigram):\", next_word_uni)\n",
        "# Bigram\n",
        "next_word_bi = predict_next_word_bigram(\"machine\", bigram, unigram, V)\n",
        "print(\"Next word prediction (Bigram) after 'machine':\", next_word_bi)\n",
        "\n",
        "# Trigram\n",
        "next_word_tri = predict_next_word_trigram(\"machine\", \"learning\", trigram, bigram, V)\n",
        "print(\"Next word prediction (Trigram) after 'machine learning':\", next_word_tri)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7BNli80Xv_A",
        "outputId": "a065162b-b03d-47d6-c678-57144342df97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Next word prediction (Unigram): is\n",
            "Next word prediction (Bigram) after 'machine': learning\n",
            "Next word prediction (Trigram) after 'machine learning': is\n"
          ]
        }
      ]
    }
  ]
}